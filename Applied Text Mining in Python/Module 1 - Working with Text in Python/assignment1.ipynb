{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "cacf7f4360d6d53c622742f64048f72c",
     "grade": false,
     "grade_id": "cell-8a754c8ce8a16eeb",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "# Assignment 1\n",
    "\n",
    "In this assignment, you'll be working with messy medical data and using regex to extract relevant infromation from the data. \n",
    "\n",
    "Each line of the `dates.txt` file corresponds to a medical note. Each note has a date that needs to be extracted, but each date is encoded in one of many formats.\n",
    "\n",
    "The goal of this assignment is to correctly identify all of the different date variants encoded in this dataset and to properly normalize and sort the dates. \n",
    "\n",
    "Here is a list of some of the variants you might encounter in this dataset:\n",
    "* 04/20/2009; 04/20/09; 4/20/09; 4/3/09\n",
    "* Mar-20-2009; Mar 20, 2009; March 20, 2009;  Mar. 20, 2009; Mar 20 2009;\n",
    "* 20 Mar 2009; 20 March 2009; 20 Mar. 2009; 20 March, 2009\n",
    "* Mar 20th, 2009; Mar 21st, 2009; Mar 22nd, 2009\n",
    "* Feb 2009; Sep 2009; Oct 2010\n",
    "* 6/2008; 12/2009\n",
    "* 2009; 2010\n",
    "\n",
    "Once you have extracted these date patterns from the text, the next step is to sort them in ascending chronological order accoring to the following rules:\n",
    "* Assume all dates in xx/xx/xx format are mm/dd/yy\n",
    "* Assume all dates where year is encoded in only two digits are years from the 1900's (e.g. 1/5/89 is January 5th, 1989)\n",
    "* If the day is missing (e.g. 9/2009), assume it is the first day of the month (e.g. September 1, 2009).\n",
    "* If the month is missing (e.g. 2010), assume it is the first of January of that year (e.g. January 1, 2010).\n",
    "* Watch out for potential typos as this is a raw, real-life derived dataset.\n",
    "\n",
    "With these rules in mind, find the correct date in each note and return a pandas Series in chronological order of the original Series' indices. **This Series should be sorted by a tie-break sort in the format of (\"extracted date\", \"original row number\").**\n",
    "\n",
    "For example if the original series was this:\n",
    "\n",
    "    0    1999\n",
    "    1    2010\n",
    "    2    1978\n",
    "    3    2015\n",
    "    4    1985\n",
    "\n",
    "Your function should return this:\n",
    "\n",
    "    0    2\n",
    "    1    4\n",
    "    2    0\n",
    "    3    1\n",
    "    4    3\n",
    "\n",
    "Your score will be calculated using [Kendall's tau](https://en.wikipedia.org/wiki/Kendall_rank_correlation_coefficient), a correlation measure for ordinal data.\n",
    "\n",
    "*This function should return a Series of length 500 and dtype int.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "4b47ce38a503bfb1f113580f394d8667",
     "grade": false,
     "grade_id": "cell-28048f36edc32946",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0         03/25/93 Total time of visit (in minutes):\\n\n",
       "1                       6/18/85 Primary Care Doctor:\\n\n",
       "2    sshe plans to move as of 7/8/71 In-Home Servic...\n",
       "3                7 on 9/27/75 Audit C Score Current:\\n\n",
       "4    2/6/96 sleep studyPain Treatment Pain Level (N...\n",
       "5                    .Per 7/06/79 Movement D/O note:\\n\n",
       "6    4, 5/18/78 Patient's thoughts about current su...\n",
       "7    10/24/89 CPT Code: 90801 - Psychiatric Diagnos...\n",
       "8                         3/7/86 SOS-10 Total Score:\\n\n",
       "9             (4/10/71)Score-1Audit C Score Current:\\n\n",
       "dtype: object"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "doc = []\n",
    "with open('assets/dates.txt') as file:\n",
    "    for line in file:\n",
    "        doc.append(line)\n",
    "\n",
    "df = pd.Series(doc)\n",
    "df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "3e58e227860ae4b02d6bdddd81506787",
     "grade": false,
     "grade_id": "cell-d6f35a51303ed6ff",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "def date_sorter():\n",
    "\n",
    "    pattern = (\n",
    "        # 04/20/2009; 04/20/09; 4/20/09; 4/3/09 (handle leading zero in months)\n",
    "        r'\\b(?:0?([1-9]|1[0-2]))[\\/\\-](\\d{1,2})[\\/\\-](\\d{2,4})\\b|'\n",
    "\n",
    "        # Mar-20-2009; Mar 20, 2009; March 20, 2009; Mar. 20, 2009; Mar 20 2009\n",
    "        r'\\b([A-Za-z]{3,})\\s+(\\d{1,2})(?:th|st|nd|rd)?,?\\s+(\\d{4})\\b|'\n",
    "\n",
    "        # Feb 2009; Sep 2009; Oct 2010\n",
    "        r'\\b([A-Za-z]{3,})\\s+(\\d{4})\\b|'\n",
    "\n",
    "        # 6/2008; 12/2009\n",
    "        r'\\b(0?[1-9]|1[0-2])/(\\d{4})\\b|'\n",
    "\n",
    "        # 2009; 2010 (skip false positives like phone numbers)\n",
    "        r'\\b(?:s|y|r)?(19\\d{2}|20\\d{2})\\b(?![-\\d])|'\n",
    "\n",
    "        # Years in parentheses (e.g., (1988-now))\n",
    "        r'\\(\\s*(19\\d{2}|20\\d{2})\\s*(?:[-–]\\s*now)?\\s*\\)|'\n",
    "\n",
    "        # Years followed by dashes (e.g., 1990--)\n",
    "        r'\\b(19\\d{2}|20\\d{2})\\b(?=\\s*[-–])'\n",
    "    )\n",
    "    # YOUR CODE HERE\n",
    "    #raise NotImplementedError()\n",
    "\n",
    "    # Extract potential dates\n",
    "    extracted = df.astype(str).str.extract(pattern)\n",
    "    \n",
    "    # Get the first non-null match in each row\n",
    "    years = extracted.bfill(axis=1).iloc[:, 0]\n",
    "    \n",
    "    # Convert to numeric, handling two-digit years\n",
    "    years = pd.to_numeric(years, errors='coerce')\n",
    "    years = years.apply(lambda x: x + 1900 if pd.notna(x) and x < 100 else x)\n",
    "    \n",
    "    # Create a tuple of (year, original_index) for tie-breaking\n",
    "    year_index_pairs = list(enumerate(years))\n",
    "    \n",
    "    # Sort by year and get the indices\n",
    "    sorted_indices = years.sort_values().index\n",
    "    \n",
    "    return pd.Series(sorted_indices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'0       39\\n1       77\\n2       68\\n3      445\\n4      410\\n5      399\\n6      450\\n7      381\\n8       15\\n9       13\\n10     369\\n11     371\\n12     358\\n13      45\\n14     397\\n15     376\\n16     124\\n17     389\\n18       4\\n19      49\\n20      23\\n21      36\\n22     395\\n23     106\\n24     105\\n25     104\\n26      62\\n27     436\\n28     415\\n29      56\\n30     420\\n31     352\\n32     405\\n33      97\\n34     412\\n35       0\\n36      35\\n37     354\\n38     452\\n39     355\\n40      22\\n41      30\\n42       8\\n43     347\\n44     388\\n45      16\\n46      95\\n47     422\\n48     393\\n49       9\\n50      91\\n51      71\\n52     424\\n53      73\\n54     432\\n55     431\\n56      92\\n57     438\\n58      18\\n59     446\\n60      32\\n61      78\\n62     402\\n63      43\\n64     391\\n65      11\\n66     118\\n67     115\\n68      25\\n69     123\\n70     384\\n71     372\\n72     108\\n73     349\\n74     392\\n75      98\\n76      84\\n77     398\\n78     350\\n79     419\\n80     427\\n81      10\\n82     448\\n83      19\\n84     433\\n85       6\\n86      34\\n87      37\\n88      14\\n89      51\\n90     377\\n91     110\\n92     111\\n93     343\\n94      47\\n95     117\\n96     440\\n97      80\\n98      41\\n99      33\\n100     52\\n101    375\\n102    344\\n103      1\\n104     86\\n105     63\\n106    430\\n107    454\\n108    425\\n109     40\\n110     38\\n111    365\\n112    366\\n113    447\\n114     72\\n115     82\\n116    380\\n117    386\\n118    385\\n119     24\\n120     20\\n121     31\\n122    102\\n123     46\\n124     70\\n125    359\\n126      5\\n127     60\\n128    453\\n129    109\\n130     96\\n131     64\\n132    416\\n133      2\\n134     67\\n135    444\\n136    119\\n137     53\\n138     12\\n139    379\\n140    362\\n141    373\\n142    351\\n143     81\\n144     44\\n145    449\\n146     85\\n147     87\\n148     89\\n149     65\\n150     61\\n151    100\\n152     59\\n153    418\\n154    417\\n155    411\\n156    407\\n157     42\\n158    396\\n159    390\\n160    107\\n161    368\\n162    442\\n163    441\\n164    382\\n165    443\\n166    421\\n167    370\\n168    346\\n169     27\\n170      3\\n171     75\\n172    103\\n173    367\\n174    356\\n175     83\\n176     48\\n177     26\\n178     74\\n179     93\\n180     28\\n181    394\\n182     79\\n183    101\\n184    403\\n185    404\\n186    112\\n187    408\\n188     90\\n189    434\\n190    121\\n191     66\\n192    439\\n193     55\\n194    361\\n195      7\\n196     29\\n197    345\\n198    409\\n199     21\\n200    353\\n201    357\\n202     17\\n203    437\\n204    413\\n205     99\\n206     50\\n207    429\\n208    426\\n209     69\\n210    364\\n211    122\\n212    374\\n213    400\\n214    387\\n215    116\\n216    363\\n217    360\\n218    120\\n219    378\\n220    348\\n221    383\\n222     54\\n223     57\\n224     58\\n225    435\\n226     76\\n227    451\\n228    401\\n229     94\\n230    423\\n231    114\\n232    113\\n233    406\\n234     88\\n235    474\\n236    486\\n237    481\\n238    214\\n239    317\\n240    473\\n241    465\\n242    204\\n243    493\\n244    495\\n245    499\\n246    466\\n247    458\\n248    470\\n249    455\\n250    489\\n251    492\\n252    485\\n253    462\\n254    476\\n255    482\\n256    233\\n257    478\\n258    477\\n259    311\\n260    483\\n261    338\\n262    321\\n263    471\\n264    456\\n265    329\\n266    328\\n267    457\\n268    494\\n269    469\\n270    414\\n271    306\\n272    484\\n273    498\\n274    339\\n275    496\\n276    270\\n277    490\\n278    428\\n279    497\\n280    491\\n281    472\\n282    273\\n283    240\\n284    227\\n285    198\\n286    244\\n287    480\\n288    463\\n289    475\\n290    464\\n291    125\\n292    126\\n293    127\\n294    128\\n295    129\\n296    130\\n297    131\\n298    132\\n299    133\\n300    134\\n301    135\\n302    136\\n303    137\\n304    138\\n305    139\\n306    140\\n307    141\\n308    142\\n309    143\\n310    144\\n311    145\\n312    146\\n313    147\\n314    148\\n315    149\\n316    150\\n317    151\\n318    152\\n319    153\\n320    154\\n321    155\\n322    156\\n323    157\\n324    158\\n325    159\\n326    160\\n327    161\\n328    162\\n329    163\\n330    164\\n331    165\\n332    166\\n333    167\\n334    168\\n335    169\\n336    170\\n337    171\\n338    172\\n339    173\\n340    174\\n341    175\\n342    176\\n343    177\\n344    178\\n345    179\\n346    180\\n347    181\\n348    182\\n349    183\\n350    184\\n351    185\\n352    186\\n353    187\\n354    188\\n355    189\\n356    190\\n357    191\\n358    192\\n359    193\\n360    194\\n361    195\\n362    196\\n363    197\\n364    199\\n365    200\\n366    201\\n367    202\\n368    203\\n369    205\\n370    206\\n371    207\\n372    208\\n373    209\\n374    210\\n375    211\\n376    212\\n377    213\\n378    215\\n379    216\\n380    217\\n381    218\\n382    219\\n383    220\\n384    221\\n385    222\\n386    223\\n387    224\\n388    225\\n389    226\\n390    228\\n391    229\\n392    230\\n393    231\\n394    232\\n395    234\\n396    235\\n397    236\\n398    237\\n399    238\\n400    239\\n401    241\\n402    242\\n403    243\\n404    245\\n405    246\\n406    247\\n407    248\\n408    249\\n409    250\\n410    251\\n411    252\\n412    253\\n413    254\\n414    255\\n415    256\\n416    257\\n417    258\\n418    259\\n419    260\\n420    261\\n421    262\\n422    263\\n423    264\\n424    265\\n425    266\\n426    267\\n427    268\\n428    269\\n429    271\\n430    272\\n431    274\\n432    275\\n433    276\\n434    277\\n435    278\\n436    279\\n437    280\\n438    281\\n439    282\\n440    283\\n441    284\\n442    285\\n443    286\\n444    287\\n445    288\\n446    289\\n447    290\\n448    291\\n449    292\\n450    293\\n451    294\\n452    295\\n453    296\\n454    297\\n455    298\\n456    299\\n457    300\\n458    301\\n459    302\\n460    303\\n461    304\\n462    305\\n463    307\\n464    308\\n465    309\\n466    310\\n467    312\\n468    313\\n469    314\\n470    315\\n471    316\\n472    318\\n473    319\\n474    320\\n475    322\\n476    323\\n477    324\\n478    325\\n479    326\\n480    327\\n481    330\\n482    331\\n483    332\\n484    333\\n485    334\\n486    335\\n487    336\\n488    337\\n489    340\\n490    341\\n491    342\\n492    459\\n493    460\\n494    461\\n495    467\\n496    468\\n497    479\\n498    487\\n499    488'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "order = date_sorter()\n",
    "\n",
    "order.to_string()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "c0843c1f0ad2aaa45fa9ac4012f1aa43",
     "grade": true,
     "grade_id": "cell-373f878879c00996",
     "locked": true,
     "points": 4,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "0e2f5bb6bab79c07a81ec366c46c4d49",
     "grade": true,
     "grade_id": "cell-0ebae76e6cd794be",
     "locked": true,
     "points": 1,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "coursera": {
   "course_slug": "python-text-mining",
   "graded_item_id": "LvcWI",
   "launcher_item_id": "krne9",
   "part_id": "Mkp1I"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "vscode": {
   "interpreter": {
    "hash": "aee8b7b246df8f9039afb4144a1f6fd8d2ca17a180786b69acc140d282b71a49"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
